---
draft: true
title: "Do single mothers have a stronger influence on their kids?"
description: |
  And how do you test that?
author:
  - name: Ruben C. Arslan
    url: https://rubenarslan.github.io
date: 03-12-2019
output:
  radix::radix_article:
    self_contained: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Yesterday, I sat down with [Lisa Reiber](https://twitter.com/_asilisa_), who is doing
her master's thesis with me. She is working on the question of the transmission
of risk preferences in families. Many of the potential models we hope to test
involve mean level predictions (e.g., children of divorcees will be more risk-averse because they learned the world is less certain). In other cases, once we get down to
which models we want to test, it is a lot less clear.

One question which I have struggled with in the past often comes up when the
phrase "strength of influence" comes up. For example, some theories say that
mothers have a stronger influence on their children's traits if the dads are absent.
Verbally, I have also seen this expressed "play a bigger role". 

Initially, one of may tend to test such a model by testing an interaction between
mother's trait and divorce. However, my argument was that in many cases, it makes more
sense to think of this differently, namely as a difference in correlations.
I didn't really have a lot of experience teaching this particular nuance. I think I left
my graduate statistics classes thinking that correlations are basically regressions
with the variables standardised.

After trying and failing to explain this verbally, I decided we should instead
generate some data. This is how I learnt about this myself. I am very fond
of simulating things to figure out stuff that others may learn through math, I just grok it more quickly. Fortunately, it worked similarly for Lisa, so I decided to share
this simple model.

We start by generating families, half of which  are divorced. Mums and dads
aren't mating assortatively in this example and all transmission is through parenting, which these hypothetical parents share equally, not genetics. Hence, in two-parent families, they both have the same influence on their child's trait `0.6 * parent`. However, in divorced families, fathers have absolutely no influence `(1 - divorce) * 0.6 * dad` ^[This is a bit internally inconsistent with them wanting to share parenting equally before, but whatever, custody battles _really_ favour mothers in this hypothetical world.] Despite all the power of parenting in this hypothetical world,
children turn out somewhat differently from their parents, which is reflected by
the final term `0.6 * rnorm(1000)`.

```{r}
library(tidyverse)
library(brms)
theme_set(theme_bw())
fam <- tibble(
  mum = rnorm(1000),
  dad = rnorm(1000),
  divorce = rep(c(0,1), each = 500),
  # child = 0.5 * mum + 0.5 * dad + 0.7 * rnorm(1000),
  child = 0.6 * mum + (1 - divorce) * 0.6 * dad + 0.6 * rnorm(1000)
)
```

So far, so good. We have a 1000 families.

Now, this is the model we would want to test.

```{r}
summary(lm(child ~ mum + divorce * dad, data = fam))
```

Nice.^[You can see how it neatly recovers all the parameters in our data-generating model.] However, in many datasets, divorced families will often have missing data for the fathers. So, we might instead test the following model; after all we think mums will have greater influence in divorced families and a lot of people seem to test "greater influence" via interaction tests.

```{r}
summary(lm(child ~ divorce * mum, data = fam))
```

But the interaction is estimated at zero! A plot to the rescue!

```{r layout='l-body-outset'}
ggplot(fam, aes(mum, child)) +
  geom_point(alpha = I(0.1)) +
  geom_smooth(method = 'lm') +
  coord_cartesian(c(-3,3), c(-3,3)) +
  facet_wrap(~ divorce, 
             labeller = labeller(divorce = c("0" = "Not divorced", "1" = "Divorced")))
```

Here, we are looking at scatter plots of mum and child by marital status. We can see visually that the slopes of the regression lines are the same. However, now we notice that the scatter around the regression line is more dispersed in the non-divorced group. I have to say, I am not sure how easily this sort of thing is noticed in plots with real data, noisier relationships, or if the moderator of influence strength is continuous.

Instead of regressions, we can also run correlations

```{r}
fam %>%  
  summarise(cor(child, mum))
fam %>% group_by(divorce) %>% 
  summarise(cor(child, mum))
```

Now, we see that the correlation between mum and child is indeed stronger in divorced families. However, I never particularly liked this approach to this problem. I find correlations harder to think about in terms of my data-generating model (you'll notice that the correlations .55 and .70 appear no where in the code above). It also becomes
difficult when moving to multiple regression, multilevel models, or non-normal data. That's why I am so happy about [`brms`](https://cloud.r-project.org/web/packages/brms/). It allows me to think about the models I want to fit in almost the same language that I use to think about data-generating models. This greatly reduces cognitive ease for me.

What would this model look like in `brms`?

```{r}
model_formula <- bf( # bf allows us to group multivariable formulas
  child ~ mum, # the regression of mum on child
  sigma ~ divorce # sigma is a reserved word. 
  # we are predicting the size of the residual variation 
  # using the divorce variable
  )
```

Let's run this model.

```{r}
mod <- brm(model_formula, 
  data = fam, cores = 4, 
  file = "divorce_importance")
summary(mod)
```

Here we go. We see clearly that there is less residual variation when the mum is the only parent. We can visualise this too. We have to use "predict" method, because this leads
`brms` to include the residuals (sigma) in the uncertainty intervals. This plot
nicely recapitulates our scatter plots from above.

```{r layout='l-body-outset'}
conds <- data.frame(divorce = c(0,1))
rownames(conds) <- c("not divorced", "divorced")
plot(marginal_effects(mod, effects = "mum", 
                 method = 'predict',
                 conditions = conds))
```

## Summary
In many cases, it really helps me (and in this case also Lisa) to generate data
according to the model I have in mind. Even such simple simulations can give us 
a sense of whether we are able to recover our model and sometimes they may lead
us to notice that we are using a word like "influence" in a very vague sense.

In personality psychology, I think a lot of us intuitively grok this problem when the two variables are the same thing measured twice (e.g. stability, consistency), but even then we sometimes lose sight of it. Maybe one reason is that for more complex models, these models are harder to fit. That's where brms comes in handy.
